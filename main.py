from datetime import datetime
from playwright.sync_api import sync_playwright
import time
import logging
import random
import json
import os
from push import push
from config import cookies, READ_NUM, PUSH_METHOD, LOG_LEVEL, READ_BOOK_LINK

# é…ç½®æ—¥å¿—æ ¼å¼
logger = logging.getLogger(__name__)
logging.basicConfig(level=LOG_LEVEL, format='%(asctime)s - %(levelname)-8s - %(message)s')

READ_TIME_REPORT_URL = "https://weread.qq.com/web/book/read"

class ReadTracker:
    def __init__(self):
        self.total_read_time_in_seconds = 0
        self.total_read_attempt = 0
        self.last_read_report_time = time.time()

    def handle_request(self, request):
        if READ_TIME_REPORT_URL in request.url:
            payload_str = request.post_data
            logging.debug(payload_str)
            if payload_str:
                try:
                    payload = json.loads(payload_str)
                    read_time = int(payload.get("rt", 0))
                    if read_time > 0:
                        self.last_read_report_time = time.time()
                        self.total_read_time_in_seconds += read_time
                        self.total_read_attempt += 1
                        logging.info(
                            f"â±ï¸ ç¬¬ {self.total_read_attempt} æ¬¡é˜…è¯»æˆåŠŸ, é˜…è¯»æ—¶é—´ï¼š{read_time}s, "
                            f"æ€»è®¡å·²é˜…è¯»ï¼š{self.total_read_time_in_seconds // 60} åˆ†é’Ÿ..."
                        )
                    if payload.get("reviews"):
                        logging.info(
                            f"ç‚¹å‡»åˆ°äº†ä¸€ä¸ªreview: {payload_str}"
                        )
                except json.JSONDecodeError:
                    logging.error("âš ï¸ post_data ä¸æ˜¯åˆæ³• JSON")


def screenshot(page, is_periodic=False):
    # æ„é€ æ–‡ä»¶åï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
    if is_periodic:
        screenshot_path = "screenshot/last.png"  # å®šæœŸæˆªå›¾ä¿å­˜è¦†ç›–
    else:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        screenshot_path = f"screenshot/fail_{timestamp}.png"
    # æˆªå›¾
    page.screenshot(path=screenshot_path)
    if is_periodic:
        logging.info(f"ğŸ–¼ï¸ å®šæœŸæˆªå›¾å·²ä¿å­˜åˆ° {screenshot_path}")
    else:
        logging.error(f"ğŸ“¸ å¼‚å¸¸æ—¶æˆªå›¾å·²ä¿å­˜åˆ° {screenshot_path}")

def mimic_reading(page):
    for i in range(30):
        x = 100 + (200 - 100) * i / 30
        y = 100 + (200 - 100) * i / 30
        page.mouse.move(x, y)
        time.sleep(1 / 10)  # æ¯æ­¥çº¦ 33 æ¯«ç§’ï¼Œæ€»å…± 1 ç§’é’Ÿ
    page.mouse.click(200, 200) # ç‚¹2ä¸‹é¼ æ ‡
    time.sleep(5)
    page.mouse.click(200, 200)
    time.sleep(random.randint(20, 30))


def move_to_next_page(page):
    button = page.locator("button[class*='renderTarget_pager_button_right']")
    button.click(timeout=10000)


def update_github_summary(message: str):
    """
    Appends a message to the GitHub Actions job summary.

    Parameters:
    - message (str): The text to append. Markdown is supported.
    """
    summary_path = os.getenv("GITHUB_STEP_SUMMARY")
    if summary_path:
        try:
            with open(summary_path, "a", encoding="utf-8") as f:
                f.write(message + "\n")
        except Exception as e:
            logging.warning(f"Failed to write to GitHub summary: {e}")
    else:
        logging.info("GITHUB_STEP_SUMMARY not set. Running outside of GitHub Actions?")


def main():
    logging.info(f"â±ï¸ å‡†å¤‡å¼€å§‹é˜…è¯»ï¼ç›®æ ‡æ—¶é•¿: {READ_NUM} åˆ†é’Ÿ...")
    logging.info(f"â±ï¸ å‡†å¤‡é˜…è¯»ï¼š{READ_BOOK_LINK}")
    # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    os.makedirs("screenshot", exist_ok=True)
    tracker = ReadTracker()

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True, args=["--disable-blink-features=AutomationControlled"])
        context = browser.new_context()

        cookies_list = [
            {
                "name": name,
                "value": value,
                "domain": ".weread.qq.com",
                "path": "/"
            }
            for name, value in cookies.items()
        ]
        context.add_cookies(cookies_list)

        page = context.new_page()
        page.goto(READ_BOOK_LINK)
        page.wait_for_timeout(5000)
        logging.info("â±ï¸ ç›®æ ‡ç½‘é¡µå·²æ‰“å¼€ã€‚")
        page.on("request", tracker.handle_request)

        while tracker.total_read_time_in_seconds < READ_NUM * 60:
            screenshot(page, is_periodic=True) # periodically screenshot
            try:
                # Check if too much time has passed without a read report
                time_since_last_report = time.time() - tracker.last_read_report_time
                if time_since_last_report > 60:
                    logging.warning(f"âš ï¸ {int(time_since_last_report)}s å†…æ— é˜…è¯»ä¸ŠæŠ¥ï¼Œå·²æˆªå›¾")
                    screenshot(page)
                elif time_since_last_report > 120:
                    # å°è¯•åˆ·æ–°é¡µé¢
                    logging.warning(f"âš ï¸ 120s å†…æ— é˜…è¯»ä¸ŠæŠ¥ï¼Œåˆ·æ–°é¡µé¢...")
                    page.goto(READ_BOOK_LINK)
                    page.wait_for_timeout(5000)
                elif time_since_last_report > 600:
                    error_message = "âš ï¸ 120s å†…æ— é˜…è¯»ä¸ŠæŠ¥ï¼Œterminating..."
                    logging.critical(error_message)
                    raise RuntimeError(error_message)
                else:
                    move_to_next_page(page)
            except Exception as e:
                logging.error(f"ç‚¹å‡»å¤±è´¥ï¼Œå¯èƒ½æ‰¾ä¸åˆ°æŒ‰é’®ï¼š{e}")
                screenshot(page)
            mimic_reading(page)

        browser.close()

    logging.info("ğŸ‰ é˜…è¯»è„šæœ¬å·²å®Œæˆï¼")

    success_message = f"ğŸ‰ å¾®ä¿¡è¯»ä¹¦è‡ªåŠ¨é˜…è¯»å®Œæˆï¼\nâ±ï¸ é˜…è¯»æ—¶é•¿ï¼š{tracker.total_read_time_in_seconds // 60} åˆ†é’Ÿã€‚"
    update_github_summary(success_message)
    if PUSH_METHOD:
        logging.info("â±ï¸ å¼€å§‹æ¨é€...")
        push(success_message, PUSH_METHOD)

main()
